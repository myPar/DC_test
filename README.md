# Задание 1

#### Решение

Данное задание требует реализовать вычленение текста по шаблону и по максимальному правдоподобию. Я решил написать python программу, которая использует готовые датасеты с городами СНГ и ищет в тексте сообщения токен максимально похожий на один из городов. 

Суммарный объём всех датасетов составляет около 60кб, что ничтожно мало по сравнению с весом любой LLM. Более того, LLM будет работать на порядок медленнее, поскольку даже один токенайзер использует словарь объёма несколько мегабайт, соответственно разбиение токенайзером уже займёт гораздо больше времени, чем сравнение всех слов сообщения со всеми городами в датасетах.

В виду этого, посчитал использование LLM в рамках данного задания нецелесообразным.

#### Описание работы
1. В качестве источника названий городов я создал у себя [БД](https://github.com/Legostaev/contry_region_city/blob/master/script.sql)

2. Для того, чтобы города с очень коротким названием не давали более хорошую метрику я удалил из датасетов города, где длина названия менее 4 символов.

3. Текст дробится на токены (слова)

4. Для каждого токена проверяем - есть ли он в датасете и в словаре доп.слов (СПБ, НСК, Сиб и т.д.). Если да - возвращаем город

5. Если совпадений нет - берём по минимальному расстоянию Хэмминга

# Задание 2

### Решение

От сервиса нам хотелось бы получать генерацию относительно креативных поздравлений, к тому же с различным выходом от вызова к вызову. Здесь как раз подойдёт генеративная LLM-модель. Более того, мне очень хотелось попробовать с такими поработать.

Я выбрал открытую, основанную на архитектуре GPT-2 модель от сбера - **ruGPT3Large** (Меня тоже смутило GPT3 в названии модели, на самом деле она основана на GPT2). В библиотеке transformers с huggingface она соответствует классу **GPT2LMHeadModel**. Больше информации об открытых моделях сбера, можно посмотреть на их [официальном GitHub](https://github.com/ai-forever/ru-gpts)

В качестве back-end фреймворка использовал fast-api+pydantic. Для работы с моделью - pytorch + transformers. Принцып работы простой - подгрузка модели, затем использование её инференса в рамках сервиса. В результате возвращаем выход модели с удалённым запросом (который пользователь указал в начале), чтобы оставить только новый сгенерированный моделью текст.

Приложение может принимает на вход два основных параметра - название праздника и имя поздравляемого. Также опционально можно указать длину генерируемой последовательности и динамичность генерации (под капотом - регулировка параметров top_k и top_p).

Сервис выдаст вариативное поздравление человека с указанным праздником.

# Как запустить у себя

Для начала требуется склонировать репозитории в директорию с проектом:

```bash
cd project_dir

git  clone https://github.com/myPar/DC_test.git
```

#### Сборка docker-контейнеров

Переходим в папку с проектом, открываем командную строку и набираем следующую команду:

```bash
docker-compose build
```

Она запустит построение docker-контейнеров и результатом будет мульти-контейнерное приложение, содержащее 2 docker-контейнера: с fast-api сервисом для поздравлений и python-приложением для угадывания городов.

#### Запуск и использование

Для запуска построенного мульти-контейнерного приложения используем команду:

```bash
docker-compose up
```

Сервис для поздравлений содержит 1-енд пойнт:
* URL: http://0.0.0.0:8080/congrat_generation/base
* HTTP method: __POST__
* Body:
    ```json
    {
        "holiday_name": "Новый год",
        "person_name": "Петя",
        "max_length": 60,
        "flexibility": "NORMAL"
    }
    ```
    последние два поля - не обязательны. Если не указаны, будут установлены значения по умолчанию.

    ```json
    {
        "holiday_name": "День рождения",
        "person_name": "Петя"
    }
    ```

    и так тоже можно:
    ```json
    {
        "holiday_name": "День рождения",
        "person_name": "Петя",
        "max_length": 100
    }
    ```
* response:
```json
    {
        "request_text": "Сгенерируй поздравление с 'Днём рождения' для Пети:",
        "generated_text": "\n\n\t\tПетя, ты родился в День Рожденья!\n\t\t   Поздравляем тебя от всей души!\n\t\t                Поздравляем и желаем долгих лет жизни!\n\t\t\n\t\tПусть у тебя всегда будет день рожденья —\n\t\t      Веселый, радостный, весёлый!\n                И пусть тебе никогда не надоест жить на белом свете!\n\n\n*"
    }
```

Сервис для поиска городов требуется запустить отдельной командой внутри его контейнера:
```bash
docker run -it dc_test-get-city-service python /get_city_service/main.py
```

Также, можете отдельно запустить baseline для создания результирующего датасета data.csv

# Демонстрация

Видео с демонстрацие работы можно посмотреть по ссылке:
https://drive.google.com/file/d/1c-o7HW-dM0uqj1vxyEAnW4jsM4J1n4rZ/view?usp=drive_link

